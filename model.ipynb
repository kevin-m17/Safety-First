{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety First!\n",
    "\n",
    "This is the Jupyter Notebook for my app, Safety First! The intention of this notebook is to create a Keras model that can be converted to CoreML (NaturalDisasterClassifier.mlmodel), which then can be used on xCode/Swift. This model builds an image classifier using a Convolutional Neural Network. The images are classified to be one of the three categories: Cyclone, Earthquake, or Flood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get Designated Inputs!\n",
    "\n",
    "Gets all the Keras libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "what's up\nkeras version  2.0.6\n"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "print(\"what's up\")\n",
    "import coremltools\n",
    "# coremltools supports Keras version 2.0.6\n",
    "print('keras version ', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Extract images and put it into pickle files.\n",
    "\n",
    "I access my image folders and create X and y pickle files (image and categories respsectively) to be used in my convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "yo\nthis is  [[223 223 224 ... 219 218 218]\n [222 223 224 ... 219 218 218]\n [222 223 224 ... 220 218 218]\n ...\n [100 100  98 ... 123 120 120]\n [ 95  94  93 ... 125 122 122]\n [ 86  89  93 ... 129 127 127]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "print(\"yo\")\n",
    "\n",
    "\n",
    "file_list = []\n",
    "class_list = []\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "# All the categories you want your neural network to detect\n",
    "CATEGORIES = [\"Cyclone\", \"Earthquake\", \"Flood\"]\n",
    "\n",
    "# The size of the images that your neural network will use\n",
    "IMG_SIZE = 50\n",
    "\n",
    "# Checking or all images in the data folder\n",
    "for category in CATEGORIES :\n",
    "\tpath = os.path.join(DATADIR, category)\n",
    "\tfor img in os.listdir(path):\n",
    "\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "print(\"this is \", img_array)\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "\tfor category in CATEGORIES :\n",
    "\t\tpath = os.path.join(DATADIR, category)\n",
    "\t\tclass_num = CATEGORIES.index(category)\n",
    "\t\tfor img in os.listdir(path):\n",
    "\t\t\ttry :\n",
    "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "\t\t\t\t# new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\t\t\t\tnew_array = cv2.resize(img_array, (50, 30))\n",
    "\t\t\t\ttraining_data.append([new_array, class_num])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tpass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] #features\n",
    "y = [] #labels\n",
    "\n",
    "for features, label in training_data:\n",
    "\tX.append(features)\n",
    "\ty.append(label)\n",
    "\n",
    "# X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "X = np.array(X).reshape(-1, 50, 30, 1)\n",
    "\n",
    "# Creating the files containing all the information about your model\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Convolutional Neural Network Construction\n",
    "\n",
    "The layers of the CNN is seen in the output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_37 (Conv2D)           (None, 48, 28, 32)        320       \n_________________________________________________________________\nmax_pooling2d_34 (MaxPooling (None, 24, 14, 32)        0         \n_________________________________________________________________\nconv2d_38 (Conv2D)           (None, 22, 12, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_35 (MaxPooling (None, 11, 6, 64)         0         \n_________________________________________________________________\nconv2d_39 (Conv2D)           (None, 9, 4, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_36 (MaxPooling (None, 4, 2, 64)          0         \n_________________________________________________________________\ndropout_26 (Dropout)         (None, 4, 2, 64)          0         \n_________________________________________________________________\nflatten_12 (Flatten)         (None, 512)               0         \n_________________________________________________________________\ndense_23 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndense_24 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_25 (Dense)             (None, 3)                 387       \n=================================================================\nTotal params: 138,307\nTrainable params: 138,307\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "# Opening the files about data\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "# normalizing data (a pixel goes from 0 to 255)\n",
    "X = X/255.0\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (5, 5), input_shape=X.shape[1:], activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "# 3 convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape = X.shape[1:], activation='relu'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2 hidden layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# print(model.summary())\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Train the data!\n",
    "\n",
    "Fit the model, and it is trained using \"callbacks_list\". As seen in the output below, our image classifying accuracy is > 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "yo\nTrain on 405 samples, validate on 45 samples\nEpoch 1/40\n405/405 [==============================] - 5s - loss: 0.2145 - acc: 0.9136 - val_loss: 1.2300 - val_acc: 0.7111\nEpoch 2/40\n405/405 [==============================] - 0s - loss: 0.2142 - acc: 0.9210 - val_loss: 1.0506 - val_acc: 0.7111\nEpoch 3/40\n405/405 [==============================] - 1s - loss: 0.1775 - acc: 0.9506 - val_loss: 1.1021 - val_acc: 0.7111\nEpoch 4/40\n405/405 [==============================] - 1s - loss: 0.1138 - acc: 0.9654 - val_loss: 1.1965 - val_acc: 0.7111\nEpoch 5/40\n405/405 [==============================] - 0s - loss: 0.1069 - acc: 0.9704 - val_loss: 1.1740 - val_acc: 0.6889\nEpoch 6/40\n405/405 [==============================] - 0s - loss: 0.0999 - acc: 0.9753 - val_loss: 1.0509 - val_acc: 0.7111\nEpoch 7/40\n405/405 [==============================] - 0s - loss: 0.0528 - acc: 0.9926 - val_loss: 1.2072 - val_acc: 0.7333\nEpoch 8/40\n405/405 [==============================] - 0s - loss: 0.0583 - acc: 0.9852 - val_loss: 1.1695 - val_acc: 0.6889\nEpoch 9/40\n405/405 [==============================] - 0s - loss: 0.0421 - acc: 0.9951 - val_loss: 1.3038 - val_acc: 0.6667\nEpoch 10/40\n405/405 [==============================] - 0s - loss: 0.0731 - acc: 0.9778 - val_loss: 1.1706 - val_acc: 0.6222\nEpoch 11/40\n405/405 [==============================] - 0s - loss: 0.0626 - acc: 0.9827 - val_loss: 1.1722 - val_acc: 0.7333\ndone\n"
    }
   ],
   "source": [
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#                 optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint_path = \"best_model.{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
    "]\n",
    "print(\"yo\")\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X, y, batch_size=32, epochs=40, callbacks=callbacks_list, validation_split=0.1)\n",
    "# model.fit(X, y, batch_size=32, epochs=40, validation_split=0.1)\n",
    "model.fit(X, y, batch_size=32, nb_epoch=40, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Create the .mlmodel to be used on xCode.\n",
    "\n",
    "These lines convert our Keras model to be usable on CoreML, which is Apple's machine learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "keras version  2.0.6\n"
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'Softmax' from 'keras.layers' (/Users/kevinmo/Documents/Natural Disaster App/actualenv/lib/python3.7/site-packages/keras/layers/__init__.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-eb0c7e0fe551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras version '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Cyclone\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Earthquake\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Flood\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Softmax' from 'keras.layers' (/Users/kevinmo/Documents/Natural Disaster App/actualenv/lib/python3.7/site-packages/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "print('keras version ', keras.__version__)\n",
    "from keras.layers import Softmax\n",
    "\n",
    "output_labels = [\"Cyclone\", \"Earthquake\", \"Flood\"]\n",
    "# output_labels = [\"0\", \"1\", \"2\"]\n",
    "\n",
    "# For the first argument, use the filename of the newest .h5 file in the notebook folder.\n",
    "coreml_mnist = coremltools.converters.keras.convert(\n",
    "    'best_model.08-0.89.h5', input_names=['image'], output_names=['output'], \n",
    "    class_labels=output_labels, image_input_names='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitactualenvvenv5e5deab83a7e437a852e472be8933af2",
   "display_name": "Python 3.7.6 64-bit ('actualenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}